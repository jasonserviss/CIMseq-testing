---
title: "Cost as a function of complexity"
author: "Jason T. Serviss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: no
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

We desired to alter the distToSliceNorm cost function to provide a penality for complexity. Here we develop several and observe their performance in response to increasing complexity.

```{r}
packages <- c(
    "sp.scRNAseq",
    "sp.scRNAseqData",
    "sp.scRNAseqTesting",
    "printr",
    "ggthemes",
    "tidyverse"
)
purrr::walk(packages, library, character.only = TRUE)
rm(packages)
```

```{r}
addComplexity <- function(uObj, k = 6, plot = TRUE) {

  #add complexity
  tsne <- getData(uObj, "tsne")
  km <- kmeans(tsne, k, iter.max = 100, nstart = 100)[[1]]
  km <- tibble(class = km, multiplet = names(km))
  
  #plot
  p <- c()
  if(plot) {
    p <- tsne %>%
    as.data.frame() %>%
    rownames_to_column(var = "multiplet") %>%
    as_tibble() %>%
    full_join(km, by = "multiplet") %>%
    mutate(class = parse_factor(class, levels = unique(class))) %>%
    ggplot() +
    geom_point(aes(x = V1, y = V2, colour = class))
  }
  
  #rename and add to spUnsupervised object
  newClass <- tibble(
    multiplet = rownames(tsne),
    classReal = getData(uObj, "classification")
  ) %>%
  full_join(km, by = "multiplet") %>%
  unite(combined, classReal, class) %>%
  pull(combined)
  
  classification(uObj) <- newClass
  return(list(uObj, p, km))
}

.makeSyntheticSlice <- function(
    cellTypes,
    fractions
){
    return(colSums(t(cellTypes) * fractions))
}

distToSliceNormE1 <- function(
    fractions,
    cellTypes,
    oneMultiplet,
    i,
    ...
){
  if("cellNumber" %in% names(list(...))) {
    l <- list(...)
    cells <- l[['cellNumber']][[2]][i]
  }
    if(sum(fractions) == 0) {
        return(999999999)
    }
    normFractions <- fractions / sum(fractions)
    cellTypes <- cellTypes/mean(cellTypes)
    a = .makeSyntheticSlice(cellTypes, normFractions)
    a <- a/mean(a)
    k <- length(which(normFractions > 0))
    n <- length(fractions)
    e <- 0.01
    sum(abs((oneMultiplet - a) / (a+1))) * (1 + ((k / log(cells)) * e))
}

distToSliceNormE2 <- function(
    fractions,
    cellTypes,
    oneMultiplet,
    i,
    ...
){
  if("cellNumber" %in% names(list(...))) {
    l <- list(...)
    cells <- l[['cellNumber']][[2]][i]
  }
    if(sum(fractions) == 0) {
        return(999999999)
    }
    normFractions <- fractions / sum(fractions)
    cellTypes <- cellTypes/mean(cellTypes)
    a = .makeSyntheticSlice(cellTypes, normFractions)
    a <- a/mean(a)
    k <- length(which(normFractions > 0))
    n <- length(fractions)
    e <- 0.0075
    sum(abs((oneMultiplet - a) / (a+1))) * (1 + ((k / log(cells)) * e))
}

distToSliceNormE3 <- function(
    fractions,
    cellTypes,
    oneMultiplet,
    i,
    ...
){
  if("cellNumber" %in% names(list(...))) {
    l <- list(...)
    cells <- l[['cellNumber']][[2]][i]
  }
    if(sum(fractions) == 0) {
        return(999999999)
    }
    normFractions <- fractions / sum(fractions)
    cellTypes <- cellTypes/mean(cellTypes)
    a = .makeSyntheticSlice(cellTypes, normFractions)
    a <- a/mean(a)
    k <- length(which(normFractions > 0))
    n <- length(fractions)
    e <- 0.005
    sum(abs((oneMultiplet - a) / (a+1))) * (1 + ((k / log(cells)) * e))
}

distToSliceNormE4 <- function(
    fractions,
    cellTypes,
    oneMultiplet,
    i,
    ...
){
  if("cellNumber" %in% names(list(...))) {
    l <- list(...)
    cells <- l[['cellNumber']][[2]][i]
  }
    if(sum(fractions) == 0) {
        return(999999999)
    }
    normFractions <- fractions / sum(fractions)
    cellTypes <- cellTypes/mean(cellTypes)
    a = .makeSyntheticSlice(cellTypes, normFractions)
    a <- a/mean(a)
    k <- length(which(normFractions > 0))
    n <- length(fractions)
    e <- 0.0025
    sum(abs((oneMultiplet - a) / (a+1))) * (1 + ((k / log(cells)) * e))
}
```

Run method and add lots of complexity.
```{r, fig.align='center', fig.height=8, fig.width=10}

sng <- str_detect(colnames(countsSorted2), "^s")
cObjSng <- spCounts(countsSorted2[, sng], countsSortedERCC2[, sng])
cObjMul <- spCounts(countsSorted2[, !sng], countsSortedERCC2[, !sng])
uObj <- spUnsupervised(cObjSng)

#rename classes
positions <- str_extract(colnames(getData(cObjSng, "counts")), "...$")
newClass <- case_when(
  positions == "E03" ~ "A375", #what is this? sorting issue?
  positions %in% paste0(sort(rep(LETTERS[1:8], 4)), c("01", "02", "03", "04")) ~ "HOS",
  positions %in% paste0(sort(rep(LETTERS[1:8], 4)), c("05", "06", "07", "08")) ~ "HCT116",
  positions %in% paste0(sort(rep(LETTERS[1:8], 4)), c("09", "10", "11", "12")) ~ "A375",
  TRUE ~ "error"
)
corresp <- getData(uObj, "classification") %>%
  tibble(oldClass = ., newClass = newClass) %>%
  distinct()

classification(uObj) <- newClass

gm <- getData(uObj, "groupMeans")
colnames(gm) <- pull(corresp, newClass)[match(colnames(gm), pull(corresp, oldClass))]
groupMeans(uObj) <- gm

tm <- getData(uObj, "tsneMeans")
tm$classification <- pull(corresp, newClass)[match(tm$classification, pull(corresp, oldClass))]
tsneMeans(uObj) <- tm

#add complexity
tmp <- addComplexity(uObj,  k = 12, plot = TRUE)
uObjComplex <- tmp[[1]]
groupMeans(uObjComplex) <- averageGroupExpression(cObjSng, getData(uObjComplex, "classification"), FALSE)
newClasses <- tmp[[3]]

#plot
tmp[[2]]

#get real results
sObj_dtsn <- spSwarm(cObjMul, uObj, distFun = "distToSliceNorm", swarmsize = 50, maxiter = 10)
sObj_dts <- spSwarm(cObjMul, uObj, distFun = "distToSlice", swarmsize = 50, maxiter = 10)
```

The testing makes the assumption that all solutions including the right answer are equally correct. Thus if a multiplet containing A375 and HCT116 is input, all solutions in the classification including these cell types should have the same (or at least very similar) costs. Below we explore if that is the actual case by providing all possible valid solutions of two (by setting the fraction to 0.5 and 0.5 for two of the possible correct answers) to the cost function. 

```{r}

####FUNCTIONS
mapComplexity <- function(distFun, oneMultiplet, cellTypes, fracs, ...) {
  map_dbl(fracs, ~distFun(., cellTypes, oneMultiplet, ...)) %>%
    as_tibble() %>%
    add_column(complexity = map_int(fracs, function(x) length(which(x > 0))))
} 

mapMultiplets <- function(distFun, multiplets, cellTypes, fracs, ...) {
  map_dfr(1:ncol(multiplets), ~mapComplexity(distFun, multiplets[, .x], cellTypes, fracs, ...), .id = "id") %>%
    mutate(id = colnames(multiplets)[as.numeric(id)])
}

mapDistFuns <- function(distFuns, multiplets, cellTypes, frac, ...) {
  map_dfr(distFuns, ~mapMultiplets(.x, multiplets, cellTypes, frac, ...), .id = "costFun") %>%
  rename(cost = value)
}
#####

#setup background data, i.e. all possible combinations of 2 which are the right answer. expect the same cost
hct <- which(str_replace(colnames(getData(uObjComplex, "groupMeans")), "(.*)_.*", "\\1") %in% c("HCT116"))
a375 <- which(str_replace(colnames(getData(uObjComplex, "groupMeans")), "(.*)_.*", "\\1") %in% c("A375"))
cmbs <- expand.grid(hct, a375)

background <- lapply(1:nrow(cmbs), function(x) {
  base <- rep(0, ncol(getData(uObjComplex, "groupMeans")))
  idx <- as.numeric(cmbs[x, ])
  base[idx] <- 1
  base / sum(base)
})

#get input for functions to calc cost
#the true answer for these multiplets is A375-HCT116
cellTypes <- getData(uObjComplex, "groupMeans")[getData(uObjComplex, "selectInd"), ]
multi <- getData(cObjMul, "counts.cpm")[getData(uObjComplex, "selectInd"), ]
subMults <- c(
  "m.NJB00204.A01", "m.NJB00204.A02", "m.NJB00204.A03", "m.NJB00204.A04",
  "m.NJB00204.B01", "m.NJB00204.B02", "m.NJB00204.B03", "m.NJB00204.B04",
  "m.NJB00204.C01", "m.NJB00204.C02"
)
multiplets <- multi[, colnames(multi) %in% subMults]

#calc cost and plot
distFuns <- list(
  distToSlice = sp.scRNAseq:::distToSlice,
  distToSliceNorm = sp.scRNAseq:::distToSliceNorm
)


cellNumber <- estimateCells(cObjSng, cObjMul) %>%
  filter(sampleType == "Multiplet") %>%
  pull(cellNumberMedian)
e <- 0.01

mapDistFuns(distFuns, multiplets, cellTypes, background, cellNumber = cellNumber, e = e) %>%
  ggplot() +
  geom_boxplot(aes(x = id, y = cost)) +
  facet_wrap(~costFun) +
  theme_few() +
  labs(
    x = "Multiplet",
    y = "Cost"
  ) +
  theme(axis.text.x = element_text(angle = 90))

```

The results indicate that the cost is not identical and therefore, some solutions are more valid than others. In other words, the cost for each multiplet is lowest only when a specific combination of the correct answers is provided.

Run the distToSlice and distToSliceNorm functions with varying complexity and look at the costs for each multiplet as a function of the complexity.

```{r}
#set up correct answers with different levels of complexity
fs <- list(
  c(0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1),
  c(0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0),
  c(0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0),
  c(0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0),
  c(0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0),
  c(0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0),
  c(0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0),
  c(0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0),
  c(0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0)
)
fs <- map(fs, function(x) x / sum(x))



mapDistFuns(distFuns, multiplets, cellTypes, fs) %>%
  ggplot() +
  geom_point(aes(x = id, y = cost, colour = complexity)) +
  facet_wrap(~costFun) +
  theme_few() +
  labs(
    x = "Multiplet",
    y = "Cost"
  ) +
  theme(axis.text.x = element_text(angle = 90))
```

We can see that in almost all cases the model with the highest complexity has the lowest cost and, vice versa, that the model with the lowest complexity has the highest cost. Due to the consistency of this result, there is some indication that the cell types in the multiplet are not best represented by one individual solution in the classification result but, instead, by a combination of all the correct results. In other words, higher complexity, in this case, provides a more correct result and, therefore, a lower cost. 

Due to the fact that, in order to develop a distance functions that penalizes complexity without sacraficing accuracy, we need a testing system that gives an equal score for all individual correct answers and, thus, the only difference in the accuracy of the solutions is their complexity. 

One possible method the need for such a testing system, which may well be impossible to develop, we may be able to develop a background model that represents the variability in costs when only correct answers with minimum complexity are provided. In this way, when the cost is within this range 

A method to accomplish this may be to randomly permute the class means after running k-means clustering (this could also be done in other ways) and, thus, in theory, making all valid answers have the same cost.

```{r}
means <- getData(uObjComplex, "groupMeans")
idx <- str_replace(colnames(means), "(.*)_.*", "\\1") %>%
  unique() %>%
  map(., function(x) {
    which(x == str_replace(colnames(means), "(.*)_.*", "\\1"))
  }) 

newNames <- map(idx, function(x) colnames(means)[x]) %>% flatten_chr()

newMeans <- idx %>%
  map_dfc(., function(y) as_tibble(t(apply(means[, y], 1, sample)))) %>%
  setNames(colnames(newNames)) %>%
  as.matrix()

rownames(newMeans) <- rownames(means)
newMeans <- newMeans[getData(uObjComplex, "selectInd"), ]
```


Re-run previous tests.
```{r}

nm <- mapDistFuns(distFuns, multiplets, newMeans, background) %>%
  mutate(test = "newMeans")

om <- mapDistFuns(distFuns, multiplets, cellTypes, background) %>%
  mutate(test = "oldMeans")

bind_rows(nm, om) %>%
  ggplot() +
  geom_boxplot(aes(x = id, y = cost, fill = test)) +
  facet_wrap(~costFun) +
  theme_few() +
  labs(
    x = "Multiplet",
    y = "Cost"
  ) +
  theme(axis.text.x = element_text(angle = 90))

```

Here we take a subset of the sorted multiplets for which multiple correct answers exist in the complex dataset (12 clusters) generated above. While still providing a correct result, we then gradually increase the complexity of the model. Cost is them plotted as a function of complexity for all multiplets.

```{r, fig.align='center', fig.height=8, fig.width=10}

distFuns <- list(
  distToSlice = sp.scRNAseq:::distToSlice,
  distToSliceNorm = sp.scRNAseq:::distToSliceNorm,
  distToSliceNormE1 = distToSliceNormE1, 
  distToSliceNormE2 = distToSliceNormE2,
  distToSliceNormE3 = distToSliceNormE3,
  distToSliceNormE4 = distToSliceNormE4
)

mapDistFuns(distFuns, multiplets, cellTypes, fs) %>%
  ggplot() +
  geom_boxplot(aes(x = factor(complexity), y = cost)) +
  facet_wrap(~costFun) +
  theme_few() +
  labs(
    x = "Model complexity",
    y = "Cost"
  )
```

Conclusions: Multiple cost functions with both a linear and exponential increase in cost with increased model complexity were developed. These will be tested with real data to evaluate their true positive and true negative rates. 